%% DISCUSSION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}
\label{section:discussion}

% TODO:
% - Add a note about large uncertainties in timescales plot.  What would we need to reduce these?  How do these uncertainties compare to uncertainties in experimental kinetic measurements?

Markov models are expected to be effective and efficient ways to statistically summarize information about the pathways (mechanism) and timescales for heterogeneous biomolecular processes such as protein folding.  
The great challenge is in defining an appropriate state space.  
Here, we have presented a new algorithm for automatically generating a set of configurational states that is appropriate for describing peptide conformational dynamics in terms of a Markov model, though we expect it to be applicable to macromolecular dynamics in general.  
The algorithm uses molecular dynamics simulations as input, and generates the state definitions using information about the temporal order of conformations seen in the trajectories.
The importance of having an automatic algorithm, \emph{i.e.}, one that requires little or no human intervention, is that without it, human bias may inadvertently produce incorrect interpretations of the mechanism of conformational change by imposing a particular view on the simulation data.
Additionally, molecular simulation datasets are becoming so large and complex that effectively summarizing the data or extracting insight becomes increasingly impractical unless the experimenter analyzes the data with a specific hypothesis in mind.
Construction of a Markov model, however, allows for a ``hypothesis-free'' investigation of conformational dynamics, provided that the state space is sufficiently well sampled.

Our algorithm is based on the availability of large numbers of molecular dynamics simulations of appropriate simulation length such as might be generated by a supercomputer or a large (possibly distributed) cluster.  
Current technology allows for the production of thousands of simulations that can be tens of nanoseconds in length, hundreds of trajectories of up to hundreds of nanoseconds in length, or dozens that are on the order of a microsecond in length.
Since our goal has been to develop Markov models that accurately characterize the time evolution of ensembles of macromolecules over experimental timescales (that can range from microseconds to milliseconds) from short simulations of single molecules, our approach places strong emphasis on the longest timescales observed in molecular simulations.
For example, recognizing that ill-formed states often result in artificially shortened timescales, we sought to find states that maximize the timescales implied by their corresponding transition matrix for a particular choice of lag time and number of states.  
This resulted in the maximization of the metastability as a computationally convenient surrogate for minimizing the internal equilibration time $\tau_{\mathrm{int}}$.
%use of the trace of the transition matrix as a figure of merit for the decomposition, a computationally convenient surrogate for the sum of state lifetimes for the entire decomposition.  
%We also seek states for which the implied timescales are stable with respect to the lag time used to construct the transition matrix, and, in particular, the decomposition where this stability is achieved at the smallest possible lag time.  
%%This produces states of greater utility in that they are also capable of describing some of the faster processes, but usually it is more difficult to achieve this stability for the longer time scales.
%% JDC: Removed this because we weren't sure what it meant.


Nonetheless, for the three data sets to which we have applied the method, there have been a number of important successes.  
For alanine dipeptide, the algorithm discovered a distinct manifold of states that consisted of conformations containing a \emph{cis}-$\omega$ peptide bond.
This manifold was discovered because it was kinetically distinct, rather than structurally distinct. 
Also, for alanine dipeptide, the method produces states that are robust and structurally very similar to the best ones produced manually, as well as kinetically indistinguishable to within statistical uncertainty according to our validation metrics.
The application of the method to the F$_s$ peptide data set produced a set of states somewhat different from those identified previously from the clustering of helical order parameters \cite{sorin:2005b}.  
The states produced by the algorithm properly identified many very long lived (metastable) conformations whose lifetimes and kinetics might determine behavior on an experimental timescale.    
The Markov model produced from this state decomposition and a 5 ns transition matrix was shown to reproduce the observed state populations over 50 ns to within statistical uncertainty.
Finally, for the application of the method to the trpzip2 peptide the states constructed were consistent with ones previously identified \cite{pitera:2006a}.  
This was very encouraging since the previously constructed states used an intramolecular hydrogen bonding criterion and the automatic algorithm utilized different observables and metrics, heavy atom RMSD and kinetics, to resolve states.  
Moreover, the automatic algorithm  more finely resolved what was considered to be the ``unfolded" ensemble into metastable states that were not identified by the decomposition based on hydrogen bonding patterns.

Therefore, the algorithm is achieving many of its design objectives.  
It provides a method for identifying and characterizing the {\em slower} degrees of freedom of a molecular system.
It correctly identifies metastable states, dividing structurally very similar conformations into multiple sets that have short times for intraconversion but long times for interconversion.  
It combines together conformations that rapidly interconvert even though they may be structurally diverse.
This is a prerequisite to capturing a concise description of the pathways for conformational changes.  
Once meaningful states are identified, the transition matrix itself encapsulates the branching ratios for various pathways and the timescales for overall relaxation to equilibrium from any arbitrary starting ensemble.  
%However, in many cases we have observed that the algorithm does not identify a clear sequence 
%of metastable states whereby protein folding can be described as marching along from 
%unfolded to more and more folded metastable conformational states.  
%Apparently, for the trpzip2 and F$_s$ peptide systems we have studied here, the folded 
%(meta)stable state is entered through transitions having low probabilities 
%from a conformationally 
%very broad (diffuse) state that consists of rapidly interconverting unfolded and partially 
%folded conformations.  
%The emerging picture also suggests that there are a number of misfolded 
%metastable states also with low probabilities for interconversion with the diffuse state of 
%unfolded conformations.  These might be considered to be off pathway traps. 
%Attempts to further resolve the diffuse state in order to produce a more stepwise view of 
%folding only results in the identification of more of these misfolded metastable, or trap, 
%states, each with decreasing population and correspondingly uncertain transition probabilities.  
%This is entirely reasonable for an algorithm designed to characterize the states and 
%transitions responsible for the \emph{slowest} relaxation processes, since these will 
%involve equilibration among the folded and various misfolded metastable states with the 
%ensemble of unfolded conformations. 
% JDC: We have to mention how we can't talk about mechanism until satisfied with states.

% WS: Might cut following paragraph to save space; 
% it is a bit peripheral and weakens the case for the method
% JDC: I think this is good, but best left for our trpzip2 paper on reproducing experimental 
% T-jump data.
%In this work, it has been assumed that the longest time scale processes are the ones of 
%interest for ultimately comparing models developed using simulation data with results from 
%kinetic experiments.  
%However, it is important to note that the quality of a dynamical model should depend to a 
%great extent on how it is to be used.  
%If a model is to be developed in order to help explain or to be compared with some 
%experimental results, the nature of the experiment should have bearing on the assessment 
%of the model, or even perhaps on its construction through the choice of optimization criteria.  
%To do this, in principle one must take into account the spectroscopic technique as well 
%as other characteristics of the experiment, such as the preparation of the distribution 
%of starting conformations (e.g., from temperature jump versus chemical denaturation 
%experiments). 
%Furthermore, it is important to recognize that there may be time scales (even long ones) 
%that are *not* important to characterize because they do not affect the temporal evolution 
%of the spectroscopic observables being monitored.  
%This may be the case for various reasons.  
%There is the possibility that the longest time scale behavior is associated with shifts in 
%the population of states that can not be observed by the experimental technique because the 
%change in the population is too small, or because the states involved have a population so 
%low that they are invisible to the experimental technique.  
%In these cases it is possible that the emphasis on characterizing the longest time scales 
%may be misplaced.

Work is ongoing to establish standards for the amount and nature of simulation data (number and length of simulations) needed to develop useful and sufficiently precise Markov models as well as investigations of the effect of quality metrics other than the trace of the transition matrix on the nature of the resulting states and time scales.
Metrics for assessing the quality of the resulting model also need to be examined to complement, or as alternatives to, seeking stability of the implied time scales with respect to lag time.
A strong candidate for this includes information theoretic-based metrics cited earlier \cite{park:2006a}. 
%Finally, since thermal control mechanisms used in simulations are known to affect different types of kinetic behavior, future work is also needed to assess the nature of these on the resulting Markov models, both in the states contructed and in the time scales implied.
Finally, alternative approaches to performing this state decomposition are a further matter of current study, such as the method of No\'{e} and coworkers appearing in this issue, motivated by much the same ideas of metastability but employing different methods for the construction of a microstate space \cite{noe:jcp:2006}.

% JDC: This paragraph needs to be shortened.
%We would like to emphasize that for a given choice of state space, the transition matrices produced from the simulation data should {\em not} be used in Markov models to describe long time behavior except for lag times long enough that Markovian behavior 
%has emerged, as implied by such indicators as invariance of the implied timescales as a function of lag time, as discussed in Section \ref{section:theory:validation} and in Reference \cite{swope:2004a}.  
%We refer to this time for the onset of Markovian behavior for the particular choice of states as the Markov time.  
%As discussed in Section \ref{section:theory:requirements-for-markovian-behavior} this time may be 
%rather long if any of the states are ill-formed in the sense that they include regions of configuration
%space that are separated by large energy barriers.  
%These barriers produce a memory effect, whereby trajectories that enter the state from one side of the barrier behave qualitatively differently from ones that enter from the other side, until an adequate amount of time has passed for many barrier crossing events within this state.  
%The Markov time corresponds
%loosely to the time for this memory to be lost for {\em all} states in the decomposition.
%Also, in Reference \cite{swope:2004a} an example illustrated how internal barriers 
%can produce anomalously fast implied time
%scales.  Consider a three state system, with states labelled A, B and C, where
%there is an internal barrier in state B, a rather high rate of transition between state A and 
%one side of state B, and also between the other side of state B and state C, but no transitions
%directly between states A and C.  Because of the
%barrier in state B, on short time scales there may be no observation of transitions between 
%between states 
%A and C.  However, transition matrices produced using too short a lag time will falsely exhibit
%a high degree of flux through state B between states A and C, resulting in anomalously short
%time scales.

A general observation about the models produced using states defined by our method is that Markovian behavior is not obtained until lag times that are less than an order of magnitude shorter than the longest timescales.
Recall that the {\em utility} of a state space depends to a large extent on how early Markovian behavior is observed compared to the processes of interest.
There are multiple possibilities for why this might be the case.
For some molecular systems, there may be no identifiable metastable states in the usual sense.  
%This could be the case if the energy landscape is complex and has a continuum of barrier heights such that virtually any state that can be defined has internal barriers comparable in height to those between states. 
The existence of experimentally observed metastable states in protein systems (\emph{e.g.}\ native, intermediate, unfolded) combined with the observation of metastable states in even models of small solvated peptides \cite{chodera:mms:2006} argues that this may be unlikely.
It could be that statistical uncertainty could be undermining both the metastability quality metric and the tests for Markovian behavior.
Alternatively, the way we establish boundaries between states may not flexible enough to adequately divide true metastable regions.  
It may also be that we simply need to allow more states to be produced, resulting in subdivision of states that have internal barriers, to reduce the Markov times. 
Both of these possibilities could in principle be easily addressed by allowing the creation of more states.
However, the creation of more states, especially ones with low populations, leads inevitably to situations where transition probabilities become statistically unreliable given the current fixed quantity of equilibrium data.  

% - There may not actually be metastable states.  If there are a continuum of barrier 
%   heights, for every state we want to define, there are always barriers of comparable 
%   height within the state.

%This focus on accurate descriptions of the longer time scale processes places strong requirements on the size and quality of our dataset.  
Long time scales are ultimately the result of infrequent events, and for even large but finite equilibrium datasets these will be small in number, with resulting small off-diagonal transition probabilities that are statistically unreliable.  
This has placed us in the particularly difficult but unavoidable situation of attempting to optimize a statistically uncertain objective function.
One solution to this problem, of course, is to consider this algorithm as only the first step of an iterative process where important states and transitions are identified, and then further simulations are performed to improve the characterization
of important regions of conformation space.  This will allow refinement of the state space
and improved precision for important selected transition probabilities.  Information
from the subsequent simulations could be combined with that from the first set using the 
selection cell approach described previously \cite{swope:2004a}.  
Selection of states, or regions of configuration space, from which further simulations should be initiated could be chosen based on uncertainty considerations \cite{singhal:2005a}.


%[OMIT:]  belief that getting the long timescales right is harder due to smaller amount of 
%uncorrelated data, so if we can do that, we should be able to get the short ones, too)

%[OMIT AS PART OF DISCUSSION ABOUT COMPARISON W/EXPT; OTHER IDEAS DISCUSSED ELSEWHERE:]
%sensitive to characterization of transitions between low population (hence poorly) 
%sampled states and, these processes might NOT be the ones of experimental interest - 
%depends on spectroscopic techniques as well as characteristics of starting state preparation

%[WHETHER TO INCLUDE THIS DEPENDS ON WHAT ELSE IS DISCUSSED ON THIS TOPIC]
%Comment on need/reqmt/desire to use equilibrated data?

%[John+Nina, PLEASE NOTE: Be sure this is mentioned briefly in the Fs peptide results section: that there is an effect on the kinetics because of the thermal control.  
%This being alright since we don't actually compare our rates, or Eric's, with EXPERIMENT.  
%However, since we do compare our states with Eric's, we might as well compare our time scales with his (ours are VERY much longer than his).  
%I think we are showing (we should discuss this) that our states and transition matrix reproduce the time evolution seen in his simulations.
%However, if our time scales are very different from his, how can his states and transition matrix also be consistent with his data?
%Discussion/analysis of effect on kinetics from thermal control is another paper.]

%[OMIT DISCUSSION OF FOLLOWING:] Can this work in the context of a true funnel?  
%(All transitions are in one direction; could defy ability to model this way.)



